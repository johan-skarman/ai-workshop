{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. LangGraph basics\n",
    "\n",
    "This notebook will very briefly go through the basics of LangGraph.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/IT-HUSET/ai-workshop-250121/blob/main/lab/3-langgraph-basics.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a><br/>"
   ],
   "id": "2c18766a23c40cad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies"
   ],
   "id": "d9ec4d2323fea145"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from attr import dataclass\n",
    "%pip install httpx~=0.28.1 openai~=1.57 --upgrade --quiet\n",
    "%pip install python-dotenv~=1.0 docarray~=0.40.0 pypdf~=5.1 --upgrade --quiet\n",
    "%pip install chromadb~=0.5.18 lark~=1.2 --upgrade --quiet\n",
    "%pip install langchain~=0.3.10 langchain_openai~=0.2.11 langchain_community~=0.3.10 langchain-chroma~=0.1.4 --upgrade --quiet\n",
    "%pip install langgraph~=0.2.56 --upgrade --quiet\n",
    "\n",
    "# If running locally, you can do this instead:\n",
    "#%pip install -r ../requirements.txt"
   ],
   "id": "8cb8fe4232df0646",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load environment variables",
   "id": "d97c393583f81a66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# If running in Google Colab, you can use this code instead:\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = userdata.get(\"ANTHROPIC_API_KEY\")"
   ],
   "id": "10c06c5d20c9d8f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup Chat Model",
   "id": "cf78763cd8b82c62"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "api_version = \"2024-10-01-preview\"\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-4o-mini\", temperature=0.0, openai_api_version=api_version)"
   ],
   "id": "e45b83462515a5f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Basic LangGraph concepts\n",
    "\n",
    "![Graph](https://github.com/IT-HUSET/ai-workshop-250121/blob/main/images/graph.png?raw=true)\n",
    "\n",
    "Below are some concepts specific to LangGraph, related to modelling logic and behaviour as graphs of nodes and edges.\n",
    "\n",
    "At its core, LangGraph models agent workflows as graphs. You define the behavior of your agents using four key components:\n",
    "\n",
    "### 1. State\n",
    "To keep track of the state of the graph, we use a state object. This object serves as the input schema for all Nodes and Edges in the graph. All nodes are expected to communicate with that schema.\n",
    "\n",
    "A state object can be anything from a simple dictionary to a complex object. The state object is passed between nodes in the graph and is updated as the graph progresses. **The main documented way** to specify the schema of a graph is by using `TypedDict`. However, Pydantic BaseModel and dataclasses are also supported.\n",
    "Read more about states [here](https://langchain-ai.github.io/langgraph/concepts/low_level/#state).\n",
    "\n",
    "A simple example of a state object using `TypedDict` can look like this:\n",
    "\n",
    "```python\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class MyState(TypedDict):\n",
    "    foo: str\n",
    "    bar: str\n",
    "```\n",
    "\n",
    "#### Messages\n",
    "Questions and instructions sent to an LLM are called messages, and these are the most common form of state. Messages come in different flavours, corresponding to different roles, for instance _**System, Human, AI, Tool**_ etc. Since having a list of messages in your state is so common, there is also a predefined state class called [`MessagesState`](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate), which makes it easy to use messages.\n",
    "\n",
    "```python\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# This state class will have an additional field called `messages`\n",
    "class MyStateWithMessages(MessagesState):\n",
    "    foo: str\n",
    "    bar: str\n",
    "```\n",
    "\n",
    "Read more about messages [here](https://python.langchain.com/docs/concepts/messages/).\n",
    "![Graph](https://github.com/IT-HUSET/ai-workshop-250121/blob/main/images/langchain-messages.png?raw=true)\n",
    "\n",
    "### 2. Nodes\n",
    "A node is a unit of work in a graph. A node can be implemented as a simple function or by using a (callable) class. Read more about nodes [here](https://langchain-ai.github.io/langgraph/concepts/low_level/#nodes).\n",
    "\n",
    "The first positional argument of a node is the **state schema** used for the graph. By default, every modification of a state field will overwrite the previous value, however it's possible to change this behaviour by using **[reducer functions](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers)**.\n",
    "\n",
    "### 3. Edges\n",
    "An edge is a connection - or a transition - between two nodes. There are different types of edges, for instance predefined extry and exit nodes, simple \"normal\" edges, and conditional edges. A **_conditional_** edge means that the transition is dynamically decided based on the state of the graph.\n",
    "\n",
    "Read more about edges [here](https://langchain-ai.github.io/langgraph/concepts/low_level/#edges).\n",
    "\n",
    "### 4. Graph\n",
    "\n",
    "The Graph is an abstraction that models an agent workflows, and is built by composing a collection of nodes and edges. Using this abstraction, you can create complex, looping workflows that evolve the State over time. And because *State* is central to the process, the **`StateGraph`** class is the main graph class to use.\n",
    "\n",
    "Before using it, the graph is compiled to perform a few basic checks on the graph structure.\n",
    "\n",
    "Read more about edges [here](https://langchain-ai.github.io/langgraph/concepts/low_level/#graphs).\n"
   ],
   "id": "4e002c8d3dca96ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build a simple Graph",
   "id": "d55d2199b1605001"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setting up the State Schema\n",
    "\n",
    "We'll begin by defining the [State](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) of the graph, using the `TypedDict` class from python's `typing` module. TypedDict is simply a dictionary with a fixed set of keys and some typing support. At runtime, itâ€™s still a regular dictionary."
   ],
   "id": "b380485871db67a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from typing import TypedDict, NotRequired\n",
    "\n",
    "# You can define optional keys by setting `total=False` or by using `NotRequired` (e.g. `NotRequired[str]`)\n",
    "class MyState(TypedDict):\n",
    "    name: str\n",
    "    graph_state: NotRequired[str]"
   ],
   "id": "79f7b2a8e67728ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Examples of use",
   "id": "5bc3ece0479125cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample_state: MyState = {\"name\": \"Zaphod Beeblebrox.\", \"graph_state\": \"I am happy!\"}\n",
    "\n",
    "# Incorrect use\n",
    "invalid_state: MyState = {\"name\": \"Zaphod Beeblebrox.\", \"age\": 42} # This will result in warning because `age` is not in the schema"
   ],
   "id": "d2218f2121ae9671",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating some Nodes\n",
    "\n",
    "In its simplest form, [Nodes](https://langchain-ai.github.io/langgraph/concepts/low_level/#nodes) are just python functions, but you can also model them as \"callable\" classes.\n",
    "\n",
    "Because the state is a `TypedDict` with schema as defined above, each node can access the key, `graph_state`, with `state['graph_state']`.\n",
    "\n",
    "By default, the new value returned by each node will override the prior state value."
   ],
   "id": "374490260d5a40ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def hello_node(state: MyState) -> MyState:\n",
    "    print(\"---Hello Node---\")\n",
    "    state[\"graph_state\"] = f\"Hello, {state['name']}!\"\n",
    "    return state\n",
    "\n",
    "def happy_node(state: MyState) -> MyState:\n",
    "    print(\"---Happy Node---\")\n",
    "    state[\"graph_state\"] = state['graph_state'] + \" You look happy!\"\n",
    "    return state\n",
    "\n",
    "def sad_node(state: MyState) -> MyState:\n",
    "    print(\"---Sad Node---\")\n",
    "    state[\"graph_state\"] = state['graph_state'] + \" You look sad...\"\n",
    "    return state"
   ],
   "id": "e17f4c6d2c110f84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e1f1160a4bd350de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Defining Edges - connecting the nodes\n",
    "\n",
    "Normal Edges are used if you want to *always* go from one node to another, for example, `START` to `node_1`.\n",
    "\n",
    "Below we define a *[conditional edge](https://langchain-ai.github.io/langgraph/concepts/low_level/#conditional-edges)*, to dynamically decide the next node to visit based on some logic."
   ],
   "id": "41df0ea22af4b3b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "from typing import Literal\n",
    "\n",
    "# Note: The type of return value (Literal) is used for validation and display/debug purposes\n",
    "def decide_mood(state) -> Literal[\"happy_node\", \"sad_node\"]:\n",
    "    # Often, we will use state to decide on the next node to visit\n",
    "    user_input = state['graph_state']\n",
    "\n",
    "    # Here, let's just do a 50 / 50 split between nodes 2, 3\n",
    "    if random.random() < 0.5:\n",
    "\n",
    "        # 50% of the time, we return Node 2\n",
    "        return \"happy_node\"\n",
    "\n",
    "    # 50% of the time, we return Node 3\n",
    "    return \"sad_node\""
   ],
   "id": "a649234ecddbbcba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Graph Construction\n",
    "\n",
    "Now, we build the graph from our components defined above.\n",
    "\n",
    "We begin by initializing a [StateGraph class](https://langchain-ai.github.io/langgraph/concepts/low_level/#stategraph) with the `MyState` class we defined above.\n",
    "\n",
    "Then, we add our nodes and edges.\n",
    "\n",
    "We use the [`START` Node, a special node](https://langchain-ai.github.io/langgraph/concepts/low_level/#start-node) that sends user input to the graph, to indicate where to start our graph.\n",
    "\n",
    "The [`END` Node](https://langchain-ai.github.io/langgraph/concepts/low_level/#end-node) is a special node that represents a terminal node.\n",
    "\n",
    "Finally, we [compile our graph](https://langchain-ai.github.io/langgraph/concepts/low_level/#compiling-your-graph) to perform a few basic checks on the graph structure.\n",
    "\n",
    "We can visualize the graph as a [Mermaid diagram](https://github.com/mermaid-js/mermaid)."
   ],
   "id": "3456645b327d4cc1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MyState)\n",
    "builder.add_node(\"hello_node\", hello_node)\n",
    "builder.add_node(\"happy_node\", happy_node)\n",
    "builder.add_node(\"sad_node\", sad_node)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"hello_node\")\n",
    "builder.add_conditional_edges(\"hello_node\", decide_mood)\n",
    "builder.add_edge(\"happy_node\", END)\n",
    "builder.add_edge(\"sad_node\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "e8640f9881c9401f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Graph Invocation\n",
    "\n",
    "The compiled graph implements the unified **[`Runnable`](https://python.langchain.com/v0.1/docs/expression_language/interface/)** protocol of **LangChain**, meaning it can be **invoked** or **streamed** in the same way as any other LangChain component.\n",
    "\n",
    "The input when invoking our graph is the initial state of the graph, defined by the state schema, i.e. `MyState` in our case.\n",
    "\n",
    "When `invoke` is called, the graph starts execution from the `START` node.\n",
    "\n",
    "It progresses through the defined nodes (`hello_node`, `happy_node` (or `sad_node`)) in order.\n",
    "\n",
    "Each node function receives the current state and returns a new value, which overrides the graph state.\n",
    "\n",
    "The execution continues until it reaches the `END` node."
   ],
   "id": "ddd7e43eff5cf884"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input: MyState = {\"name\" : \"ToBe\"}\n",
    "\n",
    "graph.invoke(input)"
   ],
   "id": "3cb997d94f823624",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "----"
   ],
   "id": "88724ed7b2d1a904"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## EXERCISE! Build your own graph\n",
    "\n",
    "**Task:**\n",
    "- Create a graph that takes a name as input, converts it into a cooler sounding name and generates a mood."
   ],
   "id": "e9bda139582aff3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Below is a skeleton for the graph.",
   "id": "5392616f478764dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STATE\n",
    "class ExerciseState(TypedDict):\n",
    "    # TODO: Add name and mood\n",
    "    pass # Remove this line\n",
    "\n",
    "# NODES\n",
    "def generate_cool_name(state: ExerciseState) -> ExerciseState:\n",
    "    print(\"---Generate Cool Name---\")\n",
    "    initial_mood = \"ðŸ˜‘\"\n",
    "    new_name = llm.invoke(f\"Generate a cool name based on the name {state['name']}. Answer with just the name.\").content\n",
    "    return {} # TODO: Return the new state\n",
    "\n",
    "def happy_node(state: ExerciseState) -> ExerciseState:\n",
    "    print(\"---Happy Node---\")\n",
    "    return {} # TODO: Return the new state\n",
    "\n",
    "def sad_node(state: ExerciseState) -> ExerciseState:\n",
    "    print(\"---Sad Node---\")\n",
    "    return {} # TODO: Return the new state\n",
    "\n",
    "\n",
    "# EDGES\n",
    "def decide_mood(state: ExerciseState) -> Literal[\"happy_node\", \"sad_node\"]:\n",
    "    name = state['name']\n",
    "    if len(name) % 2 == 0:\n",
    "        return \"happy_node\"\n",
    "    return \"sad_node\"\n",
    "\n",
    "\n",
    "# GRAPH\n",
    "# Configure nodes\n",
    "builder = StateGraph(ExerciseState)\n",
    "builder.add_node(\"generate_cool_name\", generate_cool_name)\n",
    "# TODO: Add missing nodes\n",
    "#builder.add_node(...)\n",
    "#builder.add_node(...)\n",
    "\n",
    "# Configure edges\n",
    "builder.add_edge(START, \"generate_cool_name\")\n",
    "# TODO: Add missing edges\n",
    "#builder.add_conditional_edges()\n",
    "#builder.add_edge(, END)\n",
    "#builder.add_edge(, END)\n",
    "\n",
    "# Compile and view\n",
    "graph = builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "2016bcfc3b023cde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Invoke\n",
    "graph.invoke({\"name\": \"ToBe\"})"
   ],
   "id": "e8682788ac20e670",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
