{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c92fb8f010c88f46",
   "metadata": {},
   "source": [
    "# 2. LangChain **RAG**\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/IT-HUSET/ai-workshop-250121/blob/main/lab/2-langchain-retrieval.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a><br/>\n",
    "\n",
    "Retrieval is the centerpiece of our retrieval augmented generation (RAG) flow. \n",
    "\n",
    "![RAG - indexing](https://python.langchain.com/assets/images/rag_indexing-8160f90a90a33253d0154659cf7d453f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3879bfdb834293e",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d88decc865f48d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv~=1.0 docarray~=0.40.0 pypdf~=5.1 --upgrade --quiet\n",
    "%pip install chromadb~=0.5.18 sentence-transformers~=3.3 lark~=1.2 --upgrade --quiet\n",
    "%pip install langchain~=0.3.10 langchain_openai~=0.2.11 langchain_community~=0.3.10 langchain-chroma~=0.1.4 --upgrade --quiet\n",
    "%pip install youtube-transcript-api~=0.6.3 --upgrade --quiet\n",
    "\n",
    "\n",
    "\n",
    "# If running locally, you can do this instead:\n",
    "#%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ac40a94d9832c2",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5665d22198714b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# If running in Google Colab, you can use this code instead:\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13737536f4e381",
   "metadata": {},
   "source": [
    "### Setup Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba8ccd98ee77d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "api_version = \"2024-10-01-preview\"\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-4o-mini\", temperature=0.0, openai_api_version=api_version)\n",
    "embedding_model = AzureOpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_version=api_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832574a6d0c3e64d",
   "metadata": {},
   "source": [
    "### Setup path to data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f409d95acc8198e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb3349a35a5c24",
   "metadata": {},
   "source": [
    "## Document Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd8c9139ac8eff8",
   "metadata": {},
   "source": [
    "### PDFs\n",
    "\n",
    "PDFs can be loaded in a number of different ways, but the easiest is by using the `PyPDFLoader` class. PDFs can be loaded from a local file or a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5eb5a0ee419f51",
   "metadata": {
    "height": 79,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "#loader = PyPDFLoader(\"some_local_file.pdf\")\n",
    "loader = PyPDFLoader(\"https://data.riksdagen.se/fil/CDA05163-DE71-448D-807D-747C997E8F3A\") # AI:s betydelse för framtidens arbetsmarknad och skola\n",
    "#loader = PyPDFLoader(\"https://data.riksdagen.se/fil/61B7540B-EEDD-4922-B61B-FC0A9F3AE4E2\") # 2024/25:263 AI, annan ny teknik och de mänskliga rättigheterna\n",
    "#loader = PyPDFLoader(\"https://data.riksdagen.se/fil/0D43150B-5B31-43A4-89CD-4FE0478EC6C7\") # 2024/25:263 AI, annan ny teknik och de mänskliga rättigheterna (svar)\n",
    "pdf_pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f6eb44e59b0862",
   "metadata": {},
   "source": [
    "**Each page** is a `Document`.\n",
    "\n",
    "A `Document` contains text (`page_content`) and `metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "504d73e5e178e1e1",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d009b6ea75f6d72",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Enskild motion C  \n",
      "Motion till riksdagen  \n",
      "2024/25:2055 \n",
      "av Niels Paarup-Petersen (C) \n",
      "AI:s betydelse för framtidens \n",
      "arbetsmarknad och skola \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Förslag till riksdagsbeslut \n",
      "1. Riksdagen ställer sig bakom det som anförs i motionen om att tillsätta en utredning \n",
      "med uppdrag att kartlägga behov och förutsättningar för framtidens utbildning och \n",
      "ett lärande arbetsliv och tillkännager detta för regeringen. \n",
      "2. Riksdagen ställer sig bakom det som anförs i motionen om att utforma underlag och \n"
     ]
    }
   ],
   "source": [
    "page = pdf_pages[0]\n",
    "print(page.page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c269c7625471e8",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5920471668619b3",
   "metadata": {},
   "source": [
    "### YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d26b50d46b83f97",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m loader \u001b[38;5;241m=\u001b[39m YoutubeLoader\u001b[38;5;241m.\u001b[39mfrom_youtube_url(\n\u001b[1;32m      6\u001b[0m     url, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msv\u001b[39m\u001b[38;5;124m\"\u001b[39m, add_video_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m yt_docs \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(yt_docs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# Only one document will be created when using YoutubeLoader\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "#url=\"https://www.youtube.com/watch?v=XC7BeLRm7ak\"\n",
    "url=\"https://www.youtube.com/watch?v=tflYCulLYiI\"\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    url, language=\"sv\", add_video_info=False\n",
    ")\n",
    "yt_docs = loader.load()\n",
    "assert len(yt_docs) == 1 # Only one document will be created when using YoutubeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "672e0f7834d31954",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43myt_docs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mpage_content[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m500\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "yt_docs[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db663e3e22fecad1",
   "metadata": {},
   "source": [
    "### Web Page\n",
    "\n",
    "There are a number of different ways of loading data from the web, but the easiest is by using the `WebBaseLoader` class, which uses the parser BeautifulSoup under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7ea665ea826ea32",
   "metadata": {
    "height": 79,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "page_url = \"https://world.hey.com/dhh/open-source-royalty-and-mad-kings-a8f79d16\"\n",
    "loader = WebBaseLoader(page_url)\n",
    "# loader = WebBaseLoader(page_url, header_template={\n",
    "#     'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36',\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88b4c6aad3f01817",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "web_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "622a8b922753ed1b",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Open source royalty and mad kings\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    David Heinemeier Hansson\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "  October 13, 2024\n",
      "\n",
      "\n",
      "Open source royalty and mad kings\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I'm solidly in favor of the Benevolent Dictator For Life (BDFL) model of open source stewardship. This is how projects from Linux to Python, from Laravel to Ruby, and yes, Rails, have kept their cohesion, decisiveness, and forward motion. It's a model with decades worth of achievements to its name. But it's not a mandate from heaven. It's not infalli\n"
     ]
    }
   ],
   "source": [
    "print(web_docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9503dbcac5f597e6",
   "metadata": {},
   "source": [
    "## Splitting\n",
    "\n",
    "May seem simple, but it can be a complex process that requires some thought, planning and a lot of fine-tuning and iteration.\n",
    "\n",
    "![Splitting](https://python.langchain.com/assets/images/text_splitters-7961ccc13e05e2fd7f7f58048e082f47.png)\n",
    "\n",
    "### Basic splitting\n",
    "\n",
    "The most intuitive strategy is to split documents based on their length. This simple yet effective approach ensures that each chunk doesn't exceed a specified size limit.\n",
    "\n",
    "Key benefits of length-based splitting:\n",
    "\n",
    "- Straightforward implementation\n",
    "- Consistent chunk sizes\n",
    "- Easily adaptable to different model requirements\n",
    "\n",
    "The most common splitter for splitting text on length is `RecursiveCharacterTextSplitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b739862639d69270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcc2cb676287914",
   "metadata": {},
   "source": [
    "#### Let's split the loaded PDF pages (above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3afca0677ef19cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(pdf_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "527ec27177c58737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document splits: 11\n",
      "Loaded pages: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Document splits: {len(splits)}\")\n",
    "print(f\"Loaded pages: {len(pdf_pages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96a2d56129e691ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits.extend(text_splitter.split_documents(web_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c599b63b73caa",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "Let's take our splits and embed them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1302d4f02f34a538",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b725816d4a659276",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02032002992928028, -0.014629864133894444, -0.007168493699282408, -0.005369397345930338, 0.02253752201795578, 0.012119496241211891, -0.012935365550220013, -0.003099606605246663, -0.0017677171854302287, 0.04041691869497299]\n"
     ]
    }
   ],
   "source": [
    "embedding1 = embedding_model.embed_query(sentence1)\n",
    "embedding2 = embedding_model.embed_query(sentence2)\n",
    "embedding3 = embedding_model.embed_query(sentence3)\n",
    "\n",
    "print(embedding1[:10])\n",
    "#print(len(embedding1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f58a51c809cc3a5c",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77a4134a79cc792",
   "metadata": {},
   "source": [
    "Embedding 1 and 2 should be similar (using NumPy's dot product to calculate similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75fbf6e62e65ab28",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8321187122592171"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd75bffd52683828",
   "metadata": {},
   "source": [
    "But Embedding 3 should differ more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59fd064ffce9e7d0",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15658984714299562"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24d4d8d9abe6d9c1",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11712613252353708"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c684a246d270ef12",
   "metadata": {},
   "source": [
    "## Vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8fac150025d7ae",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "408c919d7c02fcc1",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optional persist_directory to save the database\n",
    "persist_directory = './db/2-langchain-retrieval/'\n",
    "\n",
    "# Remove the directory and all files in it recursively if it exists\n",
    "import shutil\n",
    "import os\n",
    "if os.path.exists(persist_directory):\n",
    "    shutil.rmtree(persist_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85504f75bd481e25",
   "metadata": {},
   "source": [
    "#### Set up the vector database - we'll use the simple Chroma database here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b01b85f42dd12998",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['941c7de5-e8a7-46c7-8429-93c41a6d9814',\n",
       " '3b59fcd2-4df0-4fb5-800e-0d3cc98a1423',\n",
       " 'cdbe7d56-cbcb-4a8a-a136-8c5a1ef6f6cb',\n",
       " '2e1b624b-259f-498e-b567-1c1bcc37ea8b',\n",
       " '57a54eee-049a-4818-b369-9b31b0c165ee',\n",
       " '2afcea0e-b2ba-432b-bbd5-cf05d6881733',\n",
       " 'c61e3d5b-218e-4644-a6d1-1741f714396b',\n",
       " '3f42f947-acb8-4a46-aae6-20294b4bff44',\n",
       " '48ce59be-2c5d-4853-999b-fd0d33de5c95',\n",
       " '25a74018-8747-4253-8dd9-a0259508442e',\n",
       " 'd5468629-afdc-49ec-93e4-68dfcf0c2bcb',\n",
       " '2c5c3dc5-ff4c-4d61-a9b4-3a5da7786ee8',\n",
       " 'baf87f21-f406-4a2d-9303-689a97d6e585',\n",
       " '4da5e8b8-db16-4c02-b053-59196c74abc8',\n",
       " '82ab4740-874f-4305-8b21-8606ddac7473',\n",
       " '8a732880-cbc5-4d30-90b4-8beca695934d',\n",
       " '73eebe7b-6356-4071-b0d5-cb587baeaf21',\n",
       " '9ae7f757-1a00-4a78-aafd-4d6475409204',\n",
       " '3adb883c-0202-4986-9c06-81820359de74',\n",
       " 'cc197b6a-f220-44c2-b25d-8aff65aa67df',\n",
       " '1750588a-2632-44f5-ab7f-ae554c50313c',\n",
       " '66e54355-d0e9-457e-aaeb-2026662d208a',\n",
       " 'aae91f17-aa95-4222-a4b9-9b69eeb6961c',\n",
       " 'b9458957-b85d-492e-8378-a11d4bed0c1b',\n",
       " 'f1b89203-0149-4da0-af3d-de3d340bffb8',\n",
       " '95ae9b84-dcbd-4655-b947-3aa96439dac0',\n",
       " '73f10748-ecc8-4a25-8805-25547a17a1e5',\n",
       " '7be7947a-f72f-46f8-a607-cf91f154a4ea',\n",
       " '3694583d-9b3d-408b-9e6a-68e9e5d286c8',\n",
       " '3a08401b-9b6c-445c-92c4-9266f049bd61',\n",
       " 'e9177c50-01d0-4170-a36d-81c0a81432ac',\n",
       " '7f7d224b-8509-4658-b920-f02b3d20141e',\n",
       " '5f66a5ed-6e6f-4f52-bb25-58c09e26619b',\n",
       " 'dd31af57-e93e-4c71-9b20-b592d87c3984',\n",
       " '2aa214da-babe-4ce8-9627-46e57d9940ca',\n",
       " '306bb2b6-8440-4c4a-baa8-3604fb9d4c68',\n",
       " '45714330-2484-46e2-aeee-db9c616f3e95',\n",
       " 'ce33f69b-ca34-4e2a-8353-86abca70d5a0',\n",
       " '4cff5d46-c3a5-4d6a-90f3-d77d172979b2']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb = Chroma(\n",
    "    collection_name=\"2-langchain-retrieval\",\n",
    "    embedding_function=embedding_model,\n",
    "    #persist_directory=persist_directory # Optionally persist the database\n",
    ")\n",
    "\n",
    "vectordb.add_documents(documents=splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910b53c1c36919e",
   "metadata": {},
   "source": [
    "#### Let's do some similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24d2b41650ec87ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Vad betyder AI i praktiken för framtidens arbetsmarknad och kompetensbehov\"\n",
    "\n",
    "def print_docs(docs):\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"Doc {i}:\\n{doc.page_content[:200].strip()}...\\n---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bde274900a41ee9",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 0:\n",
      "2 \n",
      "Motivering \n",
      "Vad betyder AI i praktiken för framtidens arbetsmarknad och kompetensbehov? Det är \n",
      "en fråga Joakim Wernberg och hans medförfattare bland annat försökt svara på. Nedan \n",
      "motion är hämtad...\n",
      "---\n",
      "Doc 1:\n",
      "vi se till att vara förberedda med en gedigen informationsbank. Framtidens arbete med \n",
      "AI kommer mest troligen att sätta krav på ett kontinuerligt lärandebehov och en \n",
      "flexibilitet. Det handlar inte e...\n",
      "---\n",
      "Doc 2:\n",
      "ekonomin. Det kan därför bli relevant att skilja på de kompetensbehov som förändras \n",
      "snabbt från de som förändras långsammare.  \n",
      "Vilka delar av framtidens kompetensbehov kan tillgodoses med nuvarande...\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "docs = vectordb.similarity_search(question,k=3)\n",
    "# Print first result\n",
    "print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f26808a1fd9cdb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 0:\n",
      "About David Heinemeier Hansson\n",
      "      \n",
      "\n",
      "\n",
      "Made Basecamp and HEY for the underdogs as co-owner and CTO of 37signals. Created Ruby on Rails. Wrote REWORK, It Doesn't Have to Be Crazy at Work, and REMOTE....\n",
      "---\n",
      "Doc 1:\n",
      "About David Heinemeier Hansson\n",
      "      \n",
      "\n",
      "\n",
      "Made Basecamp and HEY for the underdogs as co-owner and CTO of 37signals. Created Ruby on Rails. Wrote REWORK, It Doesn't Have to Be Crazy at Work, and REMOTE....\n",
      "---\n",
      "Doc 2:\n",
      "Open source royalty and mad kings\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    David Heinemeier Hansson\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "  October 13, 2024\n",
      "\n",
      "\n",
      "Open source royalty and mad kings...\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "docs = vectordb.similarity_search(\"Who is David Heinemeier Hansson?\",k=3)\n",
    "# Print first result\n",
    "print_docs(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b720831c3857",
   "metadata": {},
   "source": [
    "### Retriever\n",
    "\n",
    "[Retrievers](https://python.langchain.com/docs/concepts/retrievers/) are responsible for taking a query and returning relevant documents. There are many types of retrieval systems exist, including vectorstores, graph databases, and relational databases. LangChain provides a uniform interface for interacting with different types of retrieval systems. The **`Retriever`** interface also implements the **`Runnable`** interface, making it possible to use it as part of a chain.\n",
    "\n",
    "When creating a Retriever, it's possible to specify configuration related to the retrieval operation, such as:\n",
    "* **`search_type`** - the type of search to perform, for instance, \"similarity\" or \"hybrid\"\n",
    "* **`search_kwargs`** - dictionary containing additional keyword arguments to pass to the search function\n",
    "    * **`k`** - the number of documents to retrieve\n",
    "    * **`score_threshold`** - the minimum similarity score required for a document to be considered relevant\n",
    "    * **`filter`** - filter by document metadata (format may be specific to the retrieval system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c2b800ff69641cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a retriever\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Invoke/query the retriever\n",
    "documents = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce25ef3277361934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 0:\n",
      "2 \n",
      "Motivering \n",
      "Vad betyder AI i praktiken för framtidens arbetsmarknad och kompetensbehov? Det är \n",
      "en fråga Joakim Wernberg och hans medförfattare bland annat försökt svara på. Nedan \n",
      "motion är hämtad...\n",
      "---\n",
      "Doc 1:\n",
      "vi se till att vara förberedda med en gedigen informationsbank. Framtidens arbete med \n",
      "AI kommer mest troligen att sätta krav på ett kontinuerligt lärandebehov och en \n",
      "flexibilitet. Det handlar inte e...\n",
      "---\n",
      "Doc 2:\n",
      "ekonomin. Det kan därför bli relevant att skilja på de kompetensbehov som förändras \n",
      "snabbt från de som förändras långsammare.  \n",
      "Vilka delar av framtidens kompetensbehov kan tillgodoses med nuvarande...\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print_docs(documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
