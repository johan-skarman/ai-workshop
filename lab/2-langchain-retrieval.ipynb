{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. LangChain **RAG**\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/IT-HUSET/ai-workshop-250121/blob/main/lab/2-langchain-retrieval.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a><br/>\n",
    "\n",
    "Retrieval is the centerpiece of our retrieval augmented generation (RAG) flow. \n",
    "\n",
    "![RAG - indexing](https://python.langchain.com/assets/images/rag_indexing-8160f90a90a33253d0154659cf7d453f.png)"
   ],
   "id": "c92fb8f010c88f46"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies"
   ],
   "id": "d3879bfdb834293e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%pip install python-dotenv~=1.0 docarray~=0.40.0 pypdf~=5.1 --upgrade --quiet\n",
    "%pip install chromadb~=0.5.18 sentence-transformers~=3.3 lark~=1.2 --upgrade --quiet\n",
    "%pip install langchain~=0.3.10 langchain_openai~=0.2.11 langchain_community~=0.3.10 langchain-chroma~=0.1.4 --upgrade --quiet\n",
    "%pip install youtube-transcript-api~=0.6.3 --upgrade --quiet\n",
    "\n",
    "\n",
    "\n",
    "# If running locally, you can do this instead:\n",
    "#%pip install -r ../requirements.txt"
   ],
   "id": "d88decc865f48d82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load environment variables",
   "id": "d2ac40a94d9832c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# If running in Google Colab, you can use this code instead:\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get(\"AZURE_OPENAI_ENDPOINT\")"
   ],
   "id": "5665d22198714b71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup Chat Model",
   "id": "e13737536f4e381"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "api_version = \"2024-10-01-preview\"\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-4o-mini\", temperature=0.0, openai_api_version=api_version)\n",
    "embedding_model = AzureOpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_version=api_version)"
   ],
   "id": "cba8ccd98ee77d87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup path to data ",
   "id": "832574a6d0c3e64d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_path = \"../data\"",
   "id": "f409d95acc8198e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Document Loading",
   "id": "66bb3349a35a5c24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### PDFs\n",
    "\n",
    "PDFs can be loaded in a number of different ways, but the easiest is by using the `PyPDFLoader` class. PDFs can be loaded from a local file or a URL."
   ],
   "id": "fdd8c9139ac8eff8"
  },
  {
   "metadata": {
    "height": 79,
    "tags": []
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "#loader = PyPDFLoader(\"some_local_file.pdf\")\n",
    "loader = PyPDFLoader(\"https://data.riksdagen.se/fil/CDA05163-DE71-448D-807D-747C997E8F3A\") # AI:s betydelse för framtidens arbetsmarknad och skola\n",
    "#loader = PyPDFLoader(\"https://data.riksdagen.se/fil/61B7540B-EEDD-4922-B61B-FC0A9F3AE4E2\") # 2024/25:263 AI, annan ny teknik och de mänskliga rättigheterna\n",
    "#loader = PyPDFLoader(\"https://data.riksdagen.se/fil/0D43150B-5B31-43A4-89CD-4FE0478EC6C7\") # 2024/25:263 AI, annan ny teknik och de mänskliga rättigheterna (svar)\n",
    "pdf_pages = loader.load()"
   ],
   "id": "ac5eb5a0ee419f51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Each page** is a `Document`.\n",
    "\n",
    "A `Document` contains text (`page_content`) and `metadata`."
   ],
   "id": "11f6eb44e59b0862"
  },
  {
   "metadata": {
    "height": 30,
    "tags": []
   },
   "cell_type": "code",
   "source": "len(pdf_pages)",
   "id": "504d73e5e178e1e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "height": 30,
    "tags": []
   },
   "cell_type": "code",
   "source": [
    "page = pdf_pages[0]\n",
    "print(page.page_content[0:500])"
   ],
   "id": "5d009b6ea75f6d72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "height": 30,
    "tags": []
   },
   "cell_type": "code",
   "source": "page.metadata",
   "id": "f7c269c7625471e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### YouTube",
   "id": "e5920471668619b3"
  },
  {
   "metadata": {
    "height": 132,
    "tags": []
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "#url=\"https://www.youtube.com/watch?v=XC7BeLRm7ak\"\n",
    "url=\"https://www.youtube.com/watch?v=tflYCulLYiI\"\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    url, language=\"sv\", add_video_info=False\n",
    ")\n",
    "yt_docs = loader.load()\n",
    "assert len(yt_docs) == 1 # Only one document will be created when using YoutubeLoader"
   ],
   "id": "9d26b50d46b83f97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "height": 30,
    "tags": []
   },
   "cell_type": "code",
   "source": "yt_docs[0].page_content[0:500]",
   "id": "672e0f7834d31954",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Web Page\n",
    "\n",
    "There are a number of different ways of loading data from the web, but the easiest is by using the `WebBaseLoader` class, which uses the parser BeautifulSoup under the hood."
   ],
   "id": "db663e3e22fecad1"
  },
  {
   "metadata": {
    "height": 79,
    "tags": []
   },
   "cell_type": "code",
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "page_url = \"https://world.hey.com/dhh/open-source-royalty-and-mad-kings-a8f79d16\"\n",
    "loader = WebBaseLoader(page_url)\n",
    "# loader = WebBaseLoader(page_url, header_template={\n",
    "#     'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36',\n",
    "# })"
   ],
   "id": "c7ea665ea826ea32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "height": 30,
    "tags": []
   },
   "cell_type": "code",
   "source": "web_docs = loader.load()",
   "id": "88b4c6aad3f01817",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "height": 30,
    "tags": []
   },
   "cell_type": "code",
   "source": "print(web_docs[0].page_content[:500])",
   "id": "622a8b922753ed1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Splitting\n",
    "\n",
    "May seem simple, but it can be a complex process that requires some thought, planning and a lot of fine-tuning and iteration.\n",
    "\n",
    "![Splitting](https://python.langchain.com/assets/images/text_splitters-7961ccc13e05e2fd7f7f58048e082f47.png)\n",
    "\n",
    "### Basic splitting\n",
    "\n",
    "The most intuitive strategy is to split documents based on their length. This simple yet effective approach ensures that each chunk doesn't exceed a specified size limit.\n",
    "\n",
    "Key benefits of length-based splitting:\n",
    "\n",
    "- Straightforward implementation\n",
    "- Consistent chunk sizes\n",
    "- Easily adaptable to different model requirements\n",
    "\n",
    "The most common splitter for splitting text on length is `RecursiveCharacterTextSplitter`."
   ],
   "id": "9503dbcac5f597e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=25\n",
    ")"
   ],
   "id": "b739862639d69270",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Let's split the loaded PDF pages (above)",
   "id": "afcc2cb676287914"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "splits = text_splitter.split_documents(pdf_pages)",
   "id": "3afca0677ef19cb5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Document splits: {len(splits)}\")\n",
    "print(f\"Loaded pages: {len(pdf_pages)}\")"
   ],
   "id": "527ec27177c58737",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "splits.extend(text_splitter.split_documents(web_docs))",
   "id": "96a2d56129e691ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Embeddings\n",
    "\n",
    "Let's take our splits and embed them."
   ],
   "id": "58c599b63b73caa"
  },
  {
   "metadata": {
    "height": 64,
    "tags": []
   },
   "cell_type": "code",
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ],
   "id": "1302d4f02f34a538",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "height": 64,
    "tags": []
   },
   "cell_type": "code",
   "source": [
    "embedding1 = embedding_model.embed_query(sentence1)\n",
    "embedding2 = embedding_model.embed_query(sentence2)\n",
    "embedding3 = embedding_model.embed_query(sentence3)\n",
    "\n",
    "print(embedding1[:10])\n",
    "#print(len(embedding1))"
   ],
   "id": "b725816d4a659276",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "height": 30,
    "tags": []
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "f58a51c809cc3a5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Embedding 1 and 2 should be similar (using NumPy's dot product to calculate similarity)",
   "id": "b77a4134a79cc792"
  },
  {
   "metadata": {
    "height": 30,
    "tags": []
   },
   "cell_type": "code",
   "source": "np.dot(embedding1, embedding2)",
   "id": "75fbf6e62e65ab28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "But Embedding 3 should differ more",
   "id": "bd75bffd52683828"
  },
  {
   "metadata": {
    "height": 30,
    "tags": []
   },
   "cell_type": "code",
   "source": "np.dot(embedding1, embedding3)",
   "id": "59fd064ffce9e7d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "height": 30,
    "tags": []
   },
   "cell_type": "code",
   "source": "np.dot(embedding2, embedding3)",
   "id": "24d4d8d9abe6d9c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Vectorstores",
   "id": "c684a246d270ef12"
  },
  {
   "metadata": {
    "height": 30,
    "tags": []
   },
   "cell_type": "code",
   "source": "from langchain_chroma import Chroma",
   "id": "d8fac150025d7ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "height": 30,
    "tags": []
   },
   "cell_type": "code",
   "source": [
    "# Optional persist_directory to save the database\n",
    "persist_directory = './db/2-langchain-retrieval/'\n",
    "\n",
    "# Remove the directory and all files in it recursively if it exists\n",
    "import shutil\n",
    "import os\n",
    "if os.path.exists(persist_directory):\n",
    "    shutil.rmtree(persist_directory)"
   ],
   "id": "408c919d7c02fcc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Set up the vector database - we'll use the simple Chroma database here",
   "id": "85504f75bd481e25"
  },
  {
   "metadata": {
    "height": 98,
    "tags": []
   },
   "cell_type": "code",
   "source": [
    "vectordb = Chroma(\n",
    "    collection_name=\"2-langchain-retrieval\",\n",
    "    embedding_function=embedding_model,\n",
    "    #persist_directory=persist_directory # Optionally persist the database\n",
    ")\n",
    "\n",
    "vectordb.add_documents(documents=splits)"
   ],
   "id": "b01b85f42dd12998",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Let's do some similarity Search",
   "id": "4910b53c1c36919e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "question = \"Vad betyder AI i praktiken för framtidens arbetsmarknad och kompetensbehov\"\n",
    "\n",
    "def print_docs(docs):\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"Doc {i}:\\n{doc.page_content[:200].strip()}...\\n---\")"
   ],
   "id": "24d2b41650ec87ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "height": 30,
    "tags": []
   },
   "cell_type": "code",
   "source": [
    "docs = vectordb.similarity_search(question,k=3)\n",
    "# Print first result\n",
    "print_docs(docs)"
   ],
   "id": "8bde274900a41ee9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "docs = vectordb.similarity_search(\"Who is David Heinemeier Hansson?\",k=3)\n",
    "# Print first result\n",
    "print_docs(docs)"
   ],
   "id": "f26808a1fd9cdb09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Retriever\n",
    "\n",
    "[Retrievers](https://python.langchain.com/docs/concepts/retrievers/) are responsible for taking a query and returning relevant documents. There are many types of retrieval systems exist, including vectorstores, graph databases, and relational databases. LangChain provides a uniform interface for interacting with different types of retrieval systems. The **`Retriever`** interface also implements the **`Runnable`** interface, making it possible to use it as part of a chain.\n",
    "\n",
    "When creating a Retriever, it's possible to specify configuration related to the retrieval operation, such as:\n",
    "* **`search_type`** - the type of search to perform, for instance, \"similarity\" or \"hybrid\"\n",
    "* **`search_kwargs`** - dictionary containing additional keyword arguments to pass to the search function\n",
    "    * **`k`** - the number of documents to retrieve\n",
    "    * **`score_threshold`** - the minimum similarity score required for a document to be considered relevant\n",
    "    * **`filter`** - filter by document metadata (format may be specific to the retrieval system)"
   ],
   "id": "697b720831c3857"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setup a retriever\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Invoke/query the retriever\n",
    "documents = retriever.invoke(question)"
   ],
   "id": "4c2b800ff69641cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print_docs(documents)",
   "id": "ce25ef3277361934",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
